{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_1000",
    "chunk_size": 512,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.0,
      "top_p": 1.0
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.652983665466309,
        "vllm:request_prefill_time_seconds": 0.16137752900249325,
        "vllm:request_decode_time_seconds": 6.490303503000177,
        "vllm:request_inference_time_seconds": 6.651681032002671,
        "time_between_tokens": 0.025452170600000695
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.650660753250122,
        "vllm:request_prefill_time_seconds": 0.16104489500867203,
        "vllm:request_decode_time_seconds": 6.488533402996836,
        "vllm:request_inference_time_seconds": 6.649578298005508,
        "time_between_tokens": 0.025445229031360143
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.65001654624939,
        "vllm:request_prefill_time_seconds": 0.16111529699992388,
        "vllm:request_decode_time_seconds": 6.487947151996195,
        "vllm:request_inference_time_seconds": 6.649062448996119,
        "time_between_tokens": 0.025442930007828216
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.647371530532837,
        "vllm:request_prefill_time_seconds": 0.15845430400804617,
        "vllm:request_decode_time_seconds": 6.488045588004752,
        "vllm:request_inference_time_seconds": 6.646499892012798,
        "time_between_tokens": 0.025443316031391185
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.641421556472778,
        "vllm:request_prefill_time_seconds": 0.16022659999725875,
        "vllm:request_decode_time_seconds": 6.480242839999846,
        "vllm:request_inference_time_seconds": 6.640469439997105,
        "time_between_tokens": 0.02541271701960724
      }
    }
  ]
}