{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_1000",
    "chunk_size": 128,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.0,
      "top_p": 1.0
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.729753494262695,
        "vllm:request_prefill_time_seconds": 0.2467109199933475,
        "vllm:request_decode_time_seconds": 6.481978974014055,
        "vllm:request_inference_time_seconds": 6.7286898940074025,
        "time_between_tokens": 0.025419525388290412
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.735595703125,
        "vllm:request_prefill_time_seconds": 0.25232506199972704,
        "vllm:request_decode_time_seconds": 6.482048786012456,
        "vllm:request_inference_time_seconds": 6.734373848012183,
        "time_between_tokens": 0.02541979916083316
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.7387778759002686,
        "vllm:request_prefill_time_seconds": 0.2532857839978533,
        "vllm:request_decode_time_seconds": 6.484265805003815,
        "vllm:request_inference_time_seconds": 6.737551589001669,
        "time_between_tokens": 0.02542849335295614
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.7315354347229,
        "vllm:request_prefill_time_seconds": 0.24902126401138958,
        "vllm:request_decode_time_seconds": 6.481551031989511,
        "vllm:request_inference_time_seconds": 6.730572296000901,
        "time_between_tokens": 0.025417847184272594
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.736715078353882,
        "vllm:request_prefill_time_seconds": 0.25417205700068735,
        "vllm:request_decode_time_seconds": 6.4816613990115,
        "vllm:request_inference_time_seconds": 6.7358334560121875,
        "time_between_tokens": 0.02541827999612353
      }
    }
  ]
}