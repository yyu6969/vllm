{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_2000",
    "chunk_size": 1024,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.0,
      "top_p": 1.0
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.870362758636475,
        "vllm:request_prefill_time_seconds": 0.2993712399911601,
        "vllm:request_decode_time_seconds": 6.569953722006176,
        "vllm:request_inference_time_seconds": 6.869324961997336,
        "time_between_tokens": 0.02576452440002422
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.857290267944336,
        "vllm:request_prefill_time_seconds": 0.2896377689903602,
        "vllm:request_decode_time_seconds": 6.566542070999276,
        "vllm:request_inference_time_seconds": 6.856179839989636,
        "time_between_tokens": 0.02575114537646775
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.85301947593689,
        "vllm:request_prefill_time_seconds": 0.28301436400215607,
        "vllm:request_decode_time_seconds": 6.568858828002703,
        "vllm:request_inference_time_seconds": 6.8518731920048594,
        "time_between_tokens": 0.025760230698049818
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.839856386184692,
        "vllm:request_prefill_time_seconds": 0.27494346199091524,
        "vllm:request_decode_time_seconds": 6.563799586001551,
        "vllm:request_inference_time_seconds": 6.838743047992466,
        "time_between_tokens": 0.025740390533339416
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.874725580215454,
        "vllm:request_prefill_time_seconds": 0.3065100729872938,
        "vllm:request_decode_time_seconds": 6.567147756999475,
        "vllm:request_inference_time_seconds": 6.873657829986769,
        "time_between_tokens": 0.025753520615684214
      }
    }
  ]
}