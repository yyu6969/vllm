{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_1000",
    "chunk_size": 2048,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.8,
      "top_p": 0.95
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.7917578220367432,
        "vllm:request_prefill_time_seconds": 0.14695028998539783,
        "vllm:request_decode_time_seconds": 0.6438726769993082,
        "vllm:request_inference_time_seconds": 0.790822966984706,
        "time_between_tokens": 0.026828028208304506
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.718294382095337,
        "vllm:request_prefill_time_seconds": 0.1465713919897098,
        "vllm:request_decode_time_seconds": 6.570803270005854,
        "vllm:request_inference_time_seconds": 6.717374661995564,
        "time_between_tokens": 0.02576785596080727
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.6970639228820801,
        "vllm:request_prefill_time_seconds": 0.1514564560202416,
        "vllm:request_decode_time_seconds": 0.5446365129901096,
        "vllm:request_inference_time_seconds": 0.6960929690103512,
        "time_between_tokens": 0.027231825649505482
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 1.2319810390472412,
        "vllm:request_prefill_time_seconds": 0.14994491898687556,
        "vllm:request_decode_time_seconds": 1.0812070470128674,
        "vllm:request_inference_time_seconds": 1.231151965999743,
        "time_between_tokens": 0.026370903585679693
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 1.2773096561431885,
        "vllm:request_prefill_time_seconds": 0.1439077729883138,
        "vllm:request_decode_time_seconds": 1.1325714529957622,
        "vllm:request_inference_time_seconds": 1.276479225984076,
        "time_between_tokens": 0.025740260295358232
      }
    }
  ]
}