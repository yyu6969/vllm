{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_1000",
    "chunk_size": 1024,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.8,
      "top_p": 0.95,
      "seed": 42
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.727938175201416,
        "vllm:request_prefill_time_seconds": 0.1516812713816762,
        "vllm:request_decode_time_seconds": 6.575141592882574,
        "vllm:request_inference_time_seconds": 6.72682286426425,
        "time_between_tokens": 0.025684146847197553
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.7234437465667725,
        "vllm:request_prefill_time_seconds": 0.14617063477635384,
        "vllm:request_decode_time_seconds": 6.576384726911783,
        "vllm:request_inference_time_seconds": 6.722555361688137,
        "time_between_tokens": 0.025689002839499153
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.730398178100586,
        "vllm:request_prefill_time_seconds": 0.15129354689270258,
        "vllm:request_decode_time_seconds": 6.578223711811006,
        "vllm:request_inference_time_seconds": 6.729517258703709,
        "time_between_tokens": 0.025696186374261742
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.728938102722168,
        "vllm:request_prefill_time_seconds": 0.15150857903063297,
        "vllm:request_decode_time_seconds": 6.576521841809154,
        "vllm:request_inference_time_seconds": 6.7280304208397865,
        "time_between_tokens": 0.025689538444567006
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 6.726097345352173,
        "vllm:request_prefill_time_seconds": 0.15169205144047737,
        "vllm:request_decode_time_seconds": 6.573294281959534,
        "vllm:request_inference_time_seconds": 6.724986333400011,
        "time_between_tokens": 0.02567693078890443
      }
    }
  ]
}