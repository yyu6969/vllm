{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_1000",
    "chunk_size": 512,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.8,
      "top_p": 0.95,
      "seed": 42
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.6180272102355957,
        "vllm:request_prefill_time_seconds": 0.1532011879990023,
        "vllm:request_decode_time_seconds": 0.46384779599975445,
        "vllm:request_inference_time_seconds": 0.6170489839987567,
        "time_between_tokens": 0.027285164470573792
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.631354808807373,
        "vllm:request_prefill_time_seconds": 0.16196389499964425,
        "vllm:request_decode_time_seconds": 0.4685849210000015,
        "vllm:request_inference_time_seconds": 0.6305488159996457,
        "time_between_tokens": 0.027563818882353028
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.6293182373046875,
        "vllm:request_prefill_time_seconds": 0.1619767590000265,
        "vllm:request_decode_time_seconds": 0.466533292999884,
        "vllm:request_inference_time_seconds": 0.6285100519999105,
        "time_between_tokens": 0.027443134882346117
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.6290771961212158,
        "vllm:request_prefill_time_seconds": 0.16206579599929682,
        "vllm:request_decode_time_seconds": 0.4662271380002494,
        "vllm:request_inference_time_seconds": 0.6282929339995462,
        "time_between_tokens": 0.027425125764720552
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 0.6230831146240234,
        "vllm:request_prefill_time_seconds": 0.15834332299891685,
        "vllm:request_decode_time_seconds": 0.4638860579998436,
        "vllm:request_inference_time_seconds": 0.6222293809987605,
        "time_between_tokens": 0.02728741517646139
      }
    }
  ]
}