{
  "experiment_info": {
    "prompt_set": "avg_prompt_tokens_4000",
    "chunk_size": 512,
    "model": "Qwen/Qwen2.5-14B-Instruct",
    "generation_params": {
      "max_tokens": 256,
      "temperature": 0.8,
      "top_p": 0.95,
      "seed": 42
    }
  },
  "requests": [
    {
      "run_index": 0,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 7.328161954879761,
        "vllm:request_prefill_time_seconds": 0.5921584106981754,
        "vllm:request_decode_time_seconds": 6.734752592630684,
        "vllm:request_inference_time_seconds": 7.32691100332886,
        "time_between_tokens": 0.02630762731496361
      }
    },
    {
      "run_index": 1,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 7.348235607147217,
        "vllm:request_prefill_time_seconds": 0.6126384120434523,
        "vllm:request_decode_time_seconds": 6.73457970097661,
        "vllm:request_inference_time_seconds": 7.3472181130200624,
        "time_between_tokens": 0.026306951956939884
      }
    },
    {
      "run_index": 2,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 7.3387346267700195,
        "vllm:request_prefill_time_seconds": 0.5966488448902965,
        "vllm:request_decode_time_seconds": 6.741237573325634,
        "vllm:request_inference_time_seconds": 7.3378864182159305,
        "time_between_tokens": 0.026332959270803258
      }
    },
    {
      "run_index": 3,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 7.357069492340088,
        "vllm:request_prefill_time_seconds": 0.6166544714942575,
        "vllm:request_decode_time_seconds": 6.7394003523513675,
        "vllm:request_inference_time_seconds": 7.356054823845625,
        "time_between_tokens": 0.02632578262637253
      }
    },
    {
      "run_index": 4,
      "batch_size": 1,
      "success": true,
      "metrics": {
        "vllm:e2e_request_latency_seconds": 7.3295533657073975,
        "vllm:request_prefill_time_seconds": 0.5948320431634784,
        "vllm:request_decode_time_seconds": 6.733732609078288,
        "vllm:request_inference_time_seconds": 7.3285646522417665,
        "time_between_tokens": 0.026303643004212063
      }
    }
  ]
}